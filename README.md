# ðŸ’€Devils-Anus

A single home for everything you need to **collect, store and explore logs** with an EFK set-up  
Here youâ€™ll only find the **Elastic Stack deployment assets**:

* **Elasticsearch** â€“ data node / master / ingest
* **Kibana** â€“ dashboards & search UI
* **Fluent Bit** â€“ log shipper (tiny, stateless)

All packaged with **Terraform + Helm** so the same recipes run on every cloud.
It's called Devils-Anus cause logging is a shit-hole.

## Repo layout

```
devils-anus/
â”œâ”€â”€ README.md
â”œâ”€â”€ .terraform/            # local state/cache (git-ignored)
â”œâ”€â”€ terraform.tfvars.example
â”œâ”€â”€ modules/               # reusable TF modules
â”‚   â””â”€â”€ elastic-stack/
â”‚        â”œâ”€â”€ main.tf
â”‚        â”œâ”€â”€ values.yaml   # Helm values
â”‚        â””â”€â”€ ...           # variables, outputs
â””â”€â”€ deployments/
â”œâ”€â”€ civo/
â”‚   â””â”€â”€ main.tf        # uses modules/elastic-stack
â””â”€â”€ digitalocean/
â””â”€â”€ main.tf
```

**Why this structure?**

| Folder                | Purpose                                                       |
|-----------------------|---------------------------------------------------------------|
| `modules/elastic-stack` | Cloud-agnostic Helm release (namespaces, PVCs, resource limits, network policies, etc.) |
| `deployments/<provider>` | One thin wrapper per provider: sets kubeconfig backend + small provider-specific overrides |
| `terraform.tfvars.*`  | Copy to `terraform.tfvars` to fill in cluster endpoint, Helm chart versions, storage class, etc. |

---

## 2 â–º Prerequisites

| Tool | Version (tested) | Notes |
|------|------------------|-------|
| Terraform | â‰¥1.6         | `brew install terraform` |
| Helm      | â‰¥3.12        | `brew install helm` |
| kubectl   | â‰¥1.28        | Matches your cluster version |
| A working **kubeconfig** that points at the target cluster (Cosmos gave you this) |

---

## 3 â–º Quick-start (DigitalOcean example)

```bash
# 1. Clone
git clone git@github.com:your-org/devils-anus.git
cd devils-anus/deployments/digitalocean

# 2. Copy & edit variables
cp ../../terraform.tfvars.example terraform.tfvars
$EDITOR terraform.tfvars    # set kubeconfig_path, storage_class, chart versions, etc.

# 3. Deploy
terraform init   # pulls helm & kubernetes providers
terraform plan   # preview
terraform apply  # deploys Elasticsearch, Kibana, Fluent Bit

# 4. Access Kibana
kubectl -n logging port-forward svc/kibana 5601:5601
open http://localhost:5601
```

> **Namespace layout**
> * `logging`â€ƒâ€” Elasticsearch StatefulSet, Kibana Deployment
> * `log-ingest` â€” Fluent Bit DaemonSet (runs on every node)

---

## 4 â–º Module variables (excerpt)

| Variable | Default | Meaning |
|----------|---------|---------|
| `es_heap_size`         | `"1g"`      | JVM heap per ES pod |
| `es_replica_count`     | `3`         | StatefulSet replicas |
| `kibana_cpu_limit`     | `"500m"`    | CPU limit |
| `storage_class`        | `""`        | Empty = default SC of cluster |
| `fluentbit_extra_args` | `[]`        | Extra CLI flags |

See `modules/elastic-stack/variables.tf` for the full list.

---

## 5 â–º Extending to another cloud

1. Create `deployments/<provider>/main.tf`
2. Point the **kubernetes** provider to that clusterâ€™s api-server.
3. Pass any provider-specific overrides (e.g., `storage_class = "gp2"`).
4. `terraform init && terraform apply`.

No changes inside `modules/elastic-stack` should be needed.

---

## 6 â–º Dev workflow

1. **Feature branch** â†’ open PR.
2. GitHub Actions lints Terraform (`tflint`) & Helm (`helm lint`).
3. If green, merge â†’ Argo CD (or Flux) pulls `main` and syncs the live cluster.

---

## 7 â–º Caveats / TODO

- [ ] Add optional Curator job or ILM for index retention
- [ ] HorizontalPodAutoscaler examples
- [ ] Docs for multi-AZ ES node topology
- [ ] Option to swap Fluent Bit for Logstash

---

## 8 â–º License

MIT Â© Your Company Name

---

Happy logging, sinner. ðŸ”¥
